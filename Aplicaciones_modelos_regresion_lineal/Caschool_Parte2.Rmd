---
title: "Caschool Parte 2"
output: pdf_document
author: "Joel Alejandro Zavala Prieto"
toc: true
---

\newpage

# Información de contacto

Mail: alejandro.zavala1001@gmail.com

Facebook: https://www.facebook.com/AlejandroZavala1001

Git: https://github.com/AlejandroZavala98

\newpage

# Descripción del problema

La base de datos caschool.RData contiene información de las calificaciones de estudiantes de puntaje de prueba de California

Una pequeña descripción de las variables de la base de datos se da a continuación

```{r, echo = FALSE, fig.height= 4.0, fig.width = 5.5, fig.align="center"}
library(knitr)
library(lmtest)
library(sandwich)
library(MASS) 

load("C:/Users/Alejandro Zavala/Zavala_Programas/Bases/caschool.RData")
kable(description, format="markdown")
```

## Modelo

Se propone el modelo

\begin{equation*}
\begin{split}
testscr_{i} &= \beta_{0} + \beta_{1}str_{i} + u_{i} \\
i &= 1,2,...,n
\end{split}
\end{equation*}

El nombre de columnas de la base de datos se muestra a continuación

```{r, echo = FALSE, fig.height= 4.0, fig.width = 5.5, fig.align="center"}
names(caschool)
```

\newpage

Mostrando las primeras observaciones de la tabla para las variables requeridas

```{r, echo = FALSE, fig.height= 4.0, fig.width = 5.5, fig.align="center"}
head_caschool <- head(caschool[,c("dist_cod","testscr","str")])
kable(head_caschool, format="markdown")
```

El modelo ajustado es

\begin{equation*}
\begin{split}
\hat{testscr_{i}} &= \hat{\beta_{0}} + \hat{\beta_{1}}str_{i} \\
i &= 1,2,...,n
\end{split}
\end{equation*}

## Visualización de los datos

Una visualización previa de los datos

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
plot(caschool$str, caschool$testscr, col = "cadetblue", lwd = 3,
     main = "Caschool", xlab = "student teacher ratio", ylab = "Testscr")
grid(nx = NULL, ny = NULL,
     lty = 2,      # Tipo de línea
     col = "gray", # Color
     lwd = 2)  
```

\newpage

La regresión del modelo es

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
ols_caschool <- lm(testscr ~ str, data = caschool)
ols_caschool 
```

# Modelo ajustado

El modelo ajustado es

\begin{equation*}
\begin{split}
\hat{testscr_{i}} &= 698.93 -2.28 str_{i} \\
i &= 1,2,...,n
\end{split}
\end{equation*}

De tal forma

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
plot(caschool$str, caschool$testscr, col = "cadetblue", lwd = 3,
     main = "Caschool", xlab = "student teacher ratio", ylab = "Testscr")
abline(ols_caschool, col = "mediumorchid4", lwd = 4)
grid(nx = NULL, ny = NULL,
     lty = 2,      # Tipo de ínea
     col = "gray", # Color
     lwd = 2)  
```

\newpage

## Inferencias respecto a los parámetros estimados

El tamaño de la muestra es:

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
ols_residuales <- residuals(ols_caschool)
n <- length(ols_residuales);n
```

Recordemos que la varianza de los estimadores se estima por:

\begin{equation*}
\begin{split}
V[\hat{\beta_{0}}] &= c_{00}\sigma^{2} \\
c_{00} &= \frac{\sum_{i=1}^{n}x_{i}}{nS_{xx}} \\
V[\hat{\beta_{1}}] &= c_{11}\sigma^{2} \\
c_{11} &= \frac{1}{S_{xx}} \\
\end{split}
\end{equation*}

Para la prueba de hipótesis

\begin{equation*}
\begin{split}
H_{0} : \beta_{i} = \beta_{i0}
\end{split}
\end{equation*}

Se usa el estadístico de prueba

\begin{equation*}
\begin{split}
Z = \frac{\hat{\beta_{i}}-\beta_{i0}}{\sigma \sqrt{c_{ii}}}
\end{split}
\end{equation*}

Que a su vez

\begin{equation*}
T = \frac{\hat{\beta_{i}}-\beta_{i0}}{S \sqrt{c_{ii}}}
\end{equation*}

Ahora queremos probar

\begin{equation*}
\begin{split}
H_{0}: \beta_{1} = 0 \ \ \text{contra} \ \ H_{a}: \beta_{1}\neq 0
\end{split}
\end{equation*}

Que tiene una distribución t de Student con n-2 grados de libertad

Recordemos que un estimador insesgado para $\sigma^{2}$ es $S^{2}$

\begin{equation*}
\begin{split}
S^{2} = \frac{SRC}{n-2}
\end{split}
\end{equation*}

\newpage

Recordemos que la suma total de cuadrados "STC"


\begin{equation*}
\begin{split}
STC = \sum_{i=1}^{n} (y_{i} -\bar{y})^{2} 
\end{split}
\end{equation*}

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
stc <- sum((caschool$testscr - mean(caschool$testscr))^2); stc
```

Recordemos que la suma explicada de cuadrados "SEC"

\begin{equation*}
\begin{split}
SEC = \sum_{i=1}^{n} (\hat{y_{i}} -\bar{y})^{2} 
\end{split}
\end{equation*}

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
ols_ajustados <- fitted(ols_caschool)
sec <- sum((ols_ajustados - mean(caschool$testscr))^2); sec
```

Recordemos que la suma de residuales cuadrados "SRC"

\begin{equation*}
\begin{split}
SRC = \sum_{i=1}^{n} (y_{i} -\hat{y_{i}})^{2} 
\end{split}
\end{equation*}

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
src <- sum(ols_residuales^2); src
```

De tal modo nuestro estimador $S$

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
estimador_s <- sqrt(src/(n-2));estimador_s
```

Calculando $S_{xx}$

\begin{equation*}
\begin{split}
S_{xx} = \sum_{i=1}^{n}(x_{i}-\bar{x})^{2}
\end{split}
\end{equation*}

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
s_xx <- sum((caschool$str-mean(caschool$str))^2); s_xx
```

Ahora para $c_{00}$

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
c00 <- (sum(caschool$str^2))/(n*s_xx);c00
```

Ahora para $c_{11}$

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
c11 <- 1/(s_xx);c11
```
Mas adelante se vera que los coeficientes $c_{ii}$ se obtienen de $(X^{t} X)^{-1}$

\newpage

Volviendo a la prueba de hipótesis

Para el estimador $\beta_{1}$ el estadístico T es:

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
t_beta1 <- ols_caschool$coefficients[2]/(estimador_s*sqrt(c11));t_beta1
```

Notemos ademas que el valor p:

\begin{equation*}
\begin{split}
p &=2P(t>t_{estimado}) \\
p &= 2P(t>-4.75) \ \ \text{es una t con 420-2=118 grados de libertad}
\end{split}
\end{equation*}

Cuyo valor p es:

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
pvalue_beta1 <- 2*pnorm(-abs(t_beta1)); pvalue_beta1
```

Si probamos

\begin{equation*}
\begin{split}
H_{0}: \beta_{0} = 0 \ \ \text{contra} \ \ H_{a}: \beta_{0}\neq 0
\end{split}
\end{equation*}

Nuestro estadistico t seria:

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
t_beta0 <- ols_caschool$coefficients[1]/(estimador_s*sqrt(c00));t_beta0
```

Cuyo valor p es:

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
pvalue_beta0 <- 2*pnorm(-abs(t_beta0)); pvalue_beta0
```

Por linea de comando

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
summary(ols_caschool)
```

## Intervalo de confianza para los parámetros estimados

Un intervalo de confianza al nivel 95% para $\beta_{i}$

\begin{equation*}
\begin{split}
\beta_{i} \pm t_{\alpha/2}S\sqrt{c_{ii}}
\end{split}
\end{equation*}

Para $\beta_{0}$

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
cbind(inf = ols_caschool$coef[1] - 1.96*estimador_s*sqrt(c00),
      sup = ols_caschool$coef[1] + 1.96*estimador_s*sqrt(c00))
```

Para $\beta_{1}$

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
cbind(inf = ols_caschool$coef[2] - 1.96*estimador_s*sqrt(c11),
      sup = ols_caschool$coef[2] + 1.96*estimador_s*sqrt(c11))
```

Por linea de comando

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
confint(object = ols_caschool, level = 0.95)
```

\newpage

# Aplicación de forma matricial

Desarrollando en forma matricial se tiene que la matrix $A = (X^{t} X)^{-1}$

```{r}
y_value <- as.matrix(caschool$testscr);
n_m <- length(y_value);
X_matrix <- matrix(c(rep(1,n),caschool$str),nrow = n_m);
# K <- ncol(X);
A_matrix <- solve(t(X_matrix) %*% X_matrix);A_matrix# A=(X^t X)^-1

```

Nuestro estimador $S^{2} \sim \sigma^{2}$ es: 

```{r}
estimador_s^{2}
```

La matrix $(X^{t} X)^{-1}$:

```{r}
A_matrix
```

Nuestros estimadores son:

```{r}
ols_beta <- A_matrix %*% (t(X_matrix) %*% y_value) ;ols_beta
```

La matrix de varianza covarianza $S^{2} (X^{t} X)^{-1}$

```{r}
cov_var <- estimador_s^{2} * A_matrix ;cov_var
```
Que por linea de comando

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
vcov(ols_caschool)
```


\newpage

# Creación de variables Dummy 

Una variable binaria (que toma o transforma información en una o mas categorias) se denomina asimismo variable indicador o a veces variable ficticia o variable dummy.

Veamos las primeras 30 obervaciones haciendo:

\begin{equation*}
\begin{split}
D_{i}= \left\{ \begin{array}{lcc}
             1 \ \ \text{Si str del distrito i-ésimo es menor a 20} \\
             0 \ \ \text{Si str del distrito i-ésimo es mayor o igual a 20}
             \end{array}
   \right.
\end{split}
\end{equation*}
```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
df_dummy <- caschool[,c("testscr","str")]   
df_dummy["dummy"] <- ifelse(df_dummy["str"] < 20, 1, 0)
kable(head(df_dummy,20), format="markdown")
```

El modelo de regresión poblacional con $D_{i}$    
\begin{equation*}
\begin{split}
testscr_{i} &= \beta_{0} + \beta_{1}D_{i} \\
i&=1,2,3,...,n    
\end{split}
\end{equation*}

Si la variale str es alta, entonces $D_{i}=0$. De tal forma la ecuación se reduce a

\begin{equation*}
\begin{split}
testscr_{i} = \beta_{0} + \epsilon_{i}
\end{split}
\end{equation*}

Pero si la variale str es baja, entonces $D_{i}=1$. De tal forma la ecuación se reduce a

\begin{equation*}
\begin{split}
testscr_{i} = \beta_{0} + \beta_{1} + \epsilon_{i} 
\end{split}
\end{equation*}

\newpage

## Regresión con variables dummy

Si realizamos una regresión al modelo, se obtiene

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
ols_dummy <- lm(testscr ~ dummy, data = df_dummy);ols_dummy
```

El modelo ajustado es:

\begin{equation*}
\begin{split}
\hat{testscr_{i}}= 649.979 + 7.372D_{i} 
\end{split}
\end{equation*}

Y un resumen general

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
summary(ols_dummy)
```

Y un intervalo de confianza para los estimadores

```{r, echo = FALSE, fig.height= 4.5, fig.width = 6.5, fig.align="center"}
confint(object = ols_dummy, level = 0.95)
```

